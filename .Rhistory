eta <- log(muhat)
W <- diag(muhat)
X1 <- rep(1,n)
X2 <- x
X <- cbind(X1,X2)
Q <- X %*% solve(t(X) %*% W %*% X) %*% t(X)
S <- sum(1/muhat) + n * sum(diag(Q))-sum(Q)
# bias for R = df * phihat/phi
bias.phi <-  -(alpha3.hat-phihat2^2)*S/n/df
ktheta <- df + df * bias.phi / phihat2
ktheta2 <- df * (2 + tau)
theta <- ktheta2 / ktheta
k <- ktheta / theta
gamma.low <- df * phihat2  / qgamma(0.975,
shape=k,
scale=theta)
gamma.upp <- df * phihat2  / qgamma(0.025,
shape=k,
scale=theta)
gamma.err[sim] <- (phi < gamma.low) |
(phi > gamma.upp)
##
## Bootstrap
##
do.bootstrap <- T
if (do.bootstrap == T) {
phihat.boots <- vector()
e. <- (y-muhat)/sqrt(muhat)
for (i in 1:N.BOOTS) {
subsample.index <- sample.index[i,]
e <- e.[subsample.index]
P.b<-sum(e^2)
phi.1.b <- P.b/df
phi.2.b <- phi.1.b / (1+sbar)
phihat.boots[i] <- phi.2.b
}
boots.int <- (df /phihat2) *quantile(phihat.boots,c(0.025,0.975))
boots.low <- (df * phihat2 ) / boots.int[2]
boots.upp <- (df * phihat2 ) / boots.int[1]
boots.err[sim] <- (phi < boots.low) |
(phi > boots.upp)
}
##
## VGAM
##
do.RR <- T
if (do.RR) {
## RR regression
tryCatch(
{
a3<-vglm(y~x,family=negbinomial(parallel=T,zero=NULL))
phihat3<-Confint.nb1(a3)$phi0
phihat3ci<-Confint.nb1(a3)$CI.phi0
vgam.err[sim] <- (phi < phihat3ci[1]) |
(phi > phihat3ci[2])
},
error=function(cond) {
message(paste('rr',y,x,cond,sep=' '))
return(NA)
}
)
}
##
## Estimating equations
##
xx <- (y-muhat)^2/muhat
s <- (y-muhat)/muhat
z <- xx - phihat2*(1+s)
z.bar <- mean(z)
num <- (sum(z))^2
denom <- sum((z-z.bar)^2)
sumz[sim] <- sum(z)^2
chis[sim] <- num/denom
q.stars <- vector()
for (b in 1:N.BOOTS) {
boots.index <- sample.index[b,]
z.star <- z[boots.index]
z.star.bar <- mean(z.star)
q.stars[b] <- (sum(z.star)^2)/sum((z.star-z.star.bar)^2)
}
q95 <- quantile(q.stars,0.95,na.rm=T)
# solve equation to get lower and upper limits of CI
roots <- getRoots(xx,s,q95,n)
ee.err[sim] <- ( roots[1] > phi ) |
( roots[2] < phi )
}
##
## end of simulations
##
# combine error rates
errorChisq <- sum(chisq.err)/N
errorGamma <- sum(gamma.err,na.rm=T)/length(which(!is.na(gamma.err)))
errorboots <- sum(boots.err,na.rm=T)/length(which(!is.na(boots.err)))
errorVGAM  <- sum(vgam.err,na.rm=T)/length(which(!is.na(vgam.err)))
errorEE    <- sum(ee.err,na.rm=T)/length(which(!is.na(ee.err)))
# convert error rates to coverage
result <- c(1-errorChisq,1-errorGamma,1-errorboots,1-errorVGAM,1-errorEE)
return(result)
}
##
## end of calcCoverage
##
print('started')
print(Sys.time())
pops <- c("Negbin","Neyman","Poisson lognormal")
betas <- rbind(c(-3,3),c(0.1,2.2),c(2.3,0.7))
ns <- c(30,100,1000)
N <- 10000
results <- vector()
counter <- 0
phis <- c(1,2,3,5)
for (pop in pops) {
for (n in ns) {
for (b in seq(1,3)) {
print(paste(Sys.time(),'counter',counter,sep=': '))
coverage <-foreach(ph = phis, .combine = rbind, .packages=c('VGAM','MASS'))  %dopar% {
calcCoverage(population=pop,
phi=ph,
n=n,
b=betas[b,],
N=N)
}
for (j in 1:length(phis)) {
counter <- counter + 1
parms <- paste(pop,phis[j],n,betas[b,1],betas[b,2],N,coverage[j,1],coverage[j,2],coverage[j,3],coverage[j,4],sep=',')
print(parms)
results[counter] <- parms
}
}
}
}
# number of bootstrap samples
N.BOOTS = 10
library(MASS)     # for "rnegbin"
library(rmutil)   # for "rinvgauss"
library(VGAM)
#library(profvis)
library(foreach)
library(doParallel)
# for testing only:
population = "Negbin"
phi = 2
n=30
b = c(-3,3)
##!!!
N = 1000
# get the roots of the quadratic, for Estimating Equations
getRoots <- function(xx,s,q95,n) {
A <- sum(s)^2 + n^2 + 2 * n * sum(s) - q95*sum((s-mean(s))^2)
B <- -2 * sum(xx)*sum(s)-2*n*sum(xx)+
2*q95*sum((xx-mean(xx))*(s-mean(s)))
C <- (sum(xx)^2)-q95*sum((xx-mean(xx))^2)
root1 <- (-B - sqrt(B^2-4*A*C))/(2*A)
root2 <- (-B + sqrt(B^2-4*A*C))/(2*A)
result <- c(root1,root2)
return(result)
}
SEQ.30 <- seq(1,30)
SEQ.100 <- seq(1,100)
SEQ.1000 <- seq(1,1000)
no_cores= 4
registerDoParallel(makeCluster(no_cores))
##
## Calculate coverage
##
X.30 <- seq(0,1,length.out=30)
X.100 <- seq(0,1,length.out=100)
X.1000 <- seq(0,1,length.out=1000)
# number of bootstrap samples
N.BOOTS = 10
create.samples <- function(n) {
if (n==30) {
the.sequence <- SEQ.30
}
if (n==100) {
the.sequence <- SEQ.100
}
if (n==1000) {
the.sequence <- SEQ.1000
}
return(sample(the.sequence,N.BOOTS*n,replace = T))
}
# indices for the bootstrap samples. Each
#    row is a bootstrap sample (the index)
sample.index.30 <- matrix(create.samples(30),nrow=N.BOOTS,ncol=30)
sample.index.100 <- matrix(create.samples(100),nrow=N.BOOTS,ncol=100)
sample.index.1000 <- matrix(create.samples(1000),nrow=N.BOOTS,ncol=1000)
calcCoverage(population,phi,n,b,N)
library(MASS)     # for "rnegbin"
library(rmutil)   # for "rinvgauss"
library(VGAM)
#library(profvis)
library(foreach)
library(doParallel)
# calculate CI's for phi, based on chisquare distribution
#   with phihat1 and phihat2, and on Gamma distribution
#   (phihat2 only), and fitting only Negative binomial
#   for now.
#
# parallel version
#   sample.index out of the inner loop
# for testing only:
population = "Negbin"
phi = 2
n=30
b = c(-3,3)
##!!!
N = 1000
# get the roots of the quadratic, for Estimating Equations
getRoots <- function(xx,s,q95,n) {
A <- sum(s)^2 + n^2 + 2 * n * sum(s) - q95*sum((s-mean(s))^2)
B <- -2 * sum(xx)*sum(s)-2*n*sum(xx)+
2*q95*sum((xx-mean(xx))*(s-mean(s)))
C <- (sum(xx)^2)-q95*sum((xx-mean(xx))^2)
root1 <- (-B - sqrt(B^2-4*A*C))/(2*A)
root2 <- (-B + sqrt(B^2-4*A*C))/(2*A)
result <- c(root1,root2)
return(result)
}
SEQ.30 <- seq(1,30)
SEQ.100 <- seq(1,100)
SEQ.1000 <- seq(1,1000)
no_cores= 4
registerDoParallel(makeCluster(no_cores))
##
## Calculate coverage
##
X.30 <- seq(0,1,length.out=30)
X.100 <- seq(0,1,length.out=100)
X.1000 <- seq(0,1,length.out=1000)
# number of bootstrap samples
N.BOOTS = 10000
# max number of x's
create.samples <- function(n) {
if (n==30) {
the.sequence <- SEQ.30
}
if (n==100) {
the.sequence <- SEQ.100
}
if (n==1000) {
the.sequence <- SEQ.1000
}
return(sample(the.sequence,N.BOOTS*n,replace = T))
}
# indices for the bootstrap samples. Each
#    row is a bootstrap sample (the index)
sample.index.30 <- matrix(create.samples(30),nrow=N.BOOTS,ncol=30)
sample.index.100 <- matrix(create.samples(100),nrow=N.BOOTS,ncol=100)
sample.index.1000 <- matrix(create.samples(1000),nrow=N.BOOTS,ncol=1000)
#profvis({
#  calcCoverage(population,phi,n,b,N)
#})
calcCoverage <- function(population,phi,n,b,N) {
sample.index <- NA
if (n==30) {
sequ=SEQ.30
x <- X.30
sample.index <- sample.index.30
}
if (n==100) {
sequ=SEQ.100
x <- X.100
sample.index <- sample.index.100
}
if (n==1000) {
sequ=SEQ.1000
x <- X.1000
sample.index <- sample.index.1000
}
# skip duplicates: For phi=1, the true population
#   is always Poisson.
if (phi==1) {
if (population != 'Negbin') {
return(NA)
}
}
parms <- paste(population,phi,n,b[1],b[2],N,sep=',')
print(parms)
set.seed(10)
beta<-c(b[1],b[2])
#x<-seq(0,1,length.out=n)
p<-length(beta)
eta<-beta[1]+beta[2]*x
mu<-exp(eta)
nu <- phi-1
mn<-mu/nu
w<-(mn+1)/mn
mx<-log(mu)-0.5*log(w)
sx<-sqrt(log(w))
# errors of CIs
chisq.err <- vector()
gamma.err <- vector()
boots.err <- vector()
vgam.err <- vector()
ee.err <- vector()
# estimates of phi
phihats2 <- vector()
phi.hats.boots <- vector()
# used by EE
chis <- vector()
sumz <- vector()
#
# start simulations
#
for (sim in 1:N) {
if (sim %% 500 == 0) { print(sim) }
# set true population
{
if (phi==1) {
y<-rpois(n,mu) }
else {
if (population == "Negbin") {
y<-rnegbin(n,mu,mn)
}
if (population == 'Neyman') {
y<-rpois(n,rpois(n,mn)*nu)
}
if (population == 'Poisson lognormal') {
y<-rpois(n,rpois(n,mn)*nu)
}
}
}
# fit Poisson model
muhat<-fitted(glm(y~x,family="poisson"))
P<-sum((y-muhat)^2/muhat)
sbar<-mean((y-muhat)/muhat)
phihat1<-P/(n-p)
phihat2<-phihat1/(1+sbar)
phihats2[sim] <- phihat2
##
## chisquare
##
df <- n-p
chisq.low <- df * phihat2  / qchisq(0.975,df=df)
chisq.upp <- df * phihat2  / qchisq(0.025,df=df)
chisq.err[sim] <- 0
if (phi < chisq.low | phi > chisq.upp) {
chisq.err[sim] <-  1
}
###
### Gamma
###
e <- y-muhat
alpha3.hat <- (1/df) * sum( (e^3/muhat))
alpha4.hat <- (1/df) * sum(e^4/muhat) - 3 * muhat* phihat2^2
tau.i <- (alpha4.hat/phihat2^2 - 2 * alpha3.hat/phihat2 + phihat2 )
tau.i <- (1/muhat) * tau.i
tau = mean(tau.i)
# work out S
eta <- log(muhat)
W <- diag(muhat)
X1 <- rep(1,n)
X2 <- x
X <- cbind(X1,X2)
Q <- X %*% solve(t(X) %*% W %*% X) %*% t(X)
S <- sum(1/muhat) + n * sum(diag(Q))-sum(Q)
# bias for R = df * phihat/phi
bias.phi <-  -(alpha3.hat-phihat2^2)*S/n/df
ktheta <- df + df * bias.phi / phihat2
ktheta2 <- df * (2 + tau)
theta <- ktheta2 / ktheta
k <- ktheta / theta
gamma.low <- df * phihat2  / qgamma(0.975,
shape=k,
scale=theta)
gamma.upp <- df * phihat2  / qgamma(0.025,
shape=k,
scale=theta)
gamma.err[sim] <- (phi < gamma.low) |
(phi > gamma.upp)
##
## Bootstrap
##
do.bootstrap <- T
if (do.bootstrap == T) {
phihat.boots <- vector()
e. <- (y-muhat)/sqrt(muhat)
for (i in 1:N.BOOTS) {
subsample.index <- sample.index[i,]
e <- e.[subsample.index]
P.b<-sum(e^2)
phi.1.b <- P.b/df
phi.2.b <- phi.1.b / (1+sbar)
phihat.boots[i] <- phi.2.b
}
boots.int <- (df /phihat2) *quantile(phihat.boots,c(0.025,0.975))
boots.low <- (df * phihat2 ) / boots.int[2]
boots.upp <- (df * phihat2 ) / boots.int[1]
boots.err[sim] <- (phi < boots.low) |
(phi > boots.upp)
}
##
## VGAM
##
do.RR <- T
if (do.RR) {
## RR regression
tryCatch(
{
a3<-vglm(y~x,family=negbinomial(parallel=T,zero=NULL))
phihat3<-Confint.nb1(a3)$phi0
phihat3ci<-Confint.nb1(a3)$CI.phi0
vgam.err[sim] <- (phi < phihat3ci[1]) |
(phi > phihat3ci[2])
},
error=function(cond) {
message(paste('rr',y,x,cond,sep=' '))
return(NA)
}
)
}
##
## Estimating equations
##
xx <- (y-muhat)^2/muhat
s <- (y-muhat)/muhat
z <- xx - phihat2*(1+s)
z.bar <- mean(z)
num <- (sum(z))^2
denom <- sum((z-z.bar)^2)
sumz[sim] <- sum(z)^2
chis[sim] <- num/denom
q.stars <- vector()
for (b in 1:N.BOOTS) {
boots.index <- sample.index[b,]
z.star <- z[boots.index]
z.star.bar <- mean(z.star)
q.stars[b] <- (sum(z.star)^2)/sum((z.star-z.star.bar)^2)
}
q95 <- quantile(q.stars,0.95,na.rm=T)
# solve equation to get lower and upper limits of CI
roots <- getRoots(xx,s,q95,n)
ee.err[sim] <- ( roots[1] > phi ) |
( roots[2] < phi )
}
##
## end of simulations
##
# combine error rates
errorChisq <- sum(chisq.err)/N
errorGamma <- sum(gamma.err,na.rm=T)/length(which(!is.na(gamma.err)))
errorboots <- sum(boots.err,na.rm=T)/length(which(!is.na(boots.err)))
errorVGAM  <- sum(vgam.err,na.rm=T)/length(which(!is.na(vgam.err)))
errorEE    <- sum(ee.err,na.rm=T)/length(which(!is.na(ee.err)))
# convert error rates to coverage
result <- c(1-errorChisq,1-errorGamma,1-errorboots,1-errorVGAM,1-errorEE)
return(result)
}
##
## end of calcCoverage
##
print('started')
print(Sys.time())
pops <- c("Negbin","Neyman","Poisson lognormal")
betas <- rbind(c(-3,3),c(0.1,2.2),c(2.3,0.7))
ns <- c(30,100,1000)
N <- 10000
results <- vector()
counter <- 0
phis <- c(1,2,3,5)
for (pop in pops) {
for (n in ns) {
for (b in seq(1,3)) {
print(paste(Sys.time(),'counter',counter,sep=': '))
coverage <-foreach(ph = phis, .combine = rbind, .packages=c('VGAM','MASS'))  %dopar% {
calcCoverage(population=pop,
phi=ph,
n=n,
b=betas[b,],
N=N)
}
for (j in 1:length(phis)) {
counter <- counter + 1
parms <- paste(pop,phis[j],n,betas[b,1],betas[b,2],N,coverage[j,1],coverage[j,2],coverage[j,3],coverage[j,4],coverage[j,5],sep=',')
print(parms)
results[counter] <- parms
}
}
}
}
write.csv(results,'results-main-par2.csv',row.names=F,quote=F)
print('finished')
print(Sys.time())
p <- gggplot() + geom_segment(aes(x=x,y=y,xend=xend,yend=yend))
p <- gggplot() + geom_segment(aes(data=df,x=x,y=y,xend=xend,yend=yend))
p <- gggplot() + geom_segment(data=df,aes(x=x,y=y,xend=xend,yend=yend))
library(ggplot2)
df <- data.frame(x=1,y=1,xend=2,yend=1)
p <- ggplot() + geom_segment(data=df,aes(x=x,y=y,xend=xend,yend=yend))
p
df2 <- data.frame(x=c(1,1),y=c(2,3),xend=c(2,2),yend=c(2,3))
df2 <- data.frame(x=c(1,1),y=c(2,3),xend=c(2,2),yend=c(2,3))
p <- p + geom_segment(data=df2,aes(x=x,y=y,xend=xend,yend=yend))
p
shiny::runApp('shinies/app6')
runApp('shinies/app6')
runApp('shinies/app6')
runApp('shinies/app6')
runApp('shinies/app6')
knitr::opts_chunk$set(echo = TRUE)
source('~/readresults7.R')
setwd('~/overdispersion')
source('~/readresults7.R')
source('~/readResults7.R')
source('readResults7.R')
results <- read.csv('results-mainpar7.csv',
stringsAsFactors = F,header=F)
setwd('~/overdispersion')
results <- read.csv('results-mainpar7.csv',
stringsAsFactors = F,header=F)
dim(results)
